import pandas as pd
import numpy as np
import os
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, accuracy_score

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø³ÛŒØ±Ù‡Ø§
DATA_PATH = os.path.join("data", "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv")
MODEL_DIR = 'models'


def train_engine():
    if not os.path.exists(MODEL_DIR): os.makedirs(MODEL_DIR)

    # Û±. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² dtypes Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø±Ù…)
    print("â³ Loading dataset...")
    df = pd.read_csv(DATA_PATH, low_memory=False)

    # Û². Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹
    df.columns = df.columns.str.strip()
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)

    # Û³. Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§
    le = LabelEncoder()
    df['Label'] = le.fit_transform(df['Label'])
    joblib.dump(le, f'{MODEL_DIR}/label_encoder.pkl')

    print(f"ğŸ“¦ Detected Categories: {list(le.classes_)}")

    # Û´. Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    X = df.drop('Label', axis=1)
    y = df['Label']

    # Ûµ. Feature Selection (Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯)
    # ØªØ±Ø§ÙÛŒÚ© Ø´Ø¨Ú©Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø²ÛŒØ§Ø¯ Ø¯Ø§Ø±Ø¯ØŒ Ù…Ø§ Û³Û° ØªØ§ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø±Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
    print("ğŸ¯ Selecting Top Features for high-speed inference...")
    temp_model = RandomForestClassifier(n_estimators=20, n_jobs=-1)
    temp_model.fit(X, y)

    importances = pd.Series(temp_model.feature_importances_, index=X.columns)
    top_features = importances.nlargest(30).index.tolist()

    # Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù†ØªØ®Ø¨ (Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ø± Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ø¨Ø¯Ø§Ù†ÛŒÙ… Ú†Ù‡ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ù„Ø§Ø²Ù… Ø§Ø³Øª)
    joblib.dump(top_features, f'{MODEL_DIR}/selected_features.pkl')

    X = X[top_features]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Û¶. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ù†Ù‡Ø§ÛŒÛŒ
    print(f"ğŸš€ Training Final Model on {len(top_features)} optimized features...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=20,  # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø­Ø¬ÛŒÙ… Ø´Ø¯Ù† ÙØ§ÛŒÙ„ Ù…Ø¯Ù„
        random_state=42,
        n_jobs=-1,
        verbose=1
    )
    model.fit(X_train, y_train)

    # Û·. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø³Ø±ÛŒØ¹
    preds = model.predict(X_test)
    print(f"\nâœ… Training Complete! Accuracy: {accuracy_score(y_test, preds):.4f}")
    print(classification_report(y_test, preds, target_names=le.classes_))

    # Û¸. Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ ÙØ´Ø±Ø¯Ù‡ Ø´Ø¯Ù‡
    joblib.dump(model, f'{MODEL_DIR}/trained_model.pkl', compress=3)
    print(f"ğŸ’¾ Optimized model saved in '{MODEL_DIR}/' folder.")


if __name__ == "__main__":
    train_engine()